{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, n_inputs, learning_rate=0.01, n_iters=100, random_state=None):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.random_state = random_state\n",
        "        self.n_outputs = 1\n",
        "\n",
        "    def init_weights(self):\n",
        "        rng = np.random.RandomState(self.random_state) if self.random_state else np.random\n",
        "        self.weights = rng.uniform(low=-0.1, high=0.1, size=(self.n_inputs, self.n_outputs))\n",
        "        self.bias = rng.uniform(low=-0.1, high=0.1, size=(self.n_outputs,))\n",
        "    def activation_function(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        a = self.activation_function(z)\n",
        "        return np.where(a >= 0.5, 1, 0).flatten()  # Порог 0.5, flatten для совместимости с accuracy_score\n",
        "\n",
        "    def train(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.n_inputs = n_features\n",
        "\n",
        "        # Инициализация весов и смещений\n",
        "        self.init_weights()\n",
        "\n",
        "        # Инициализация общей ошибки и коррекций весов\n",
        "        E_total = 0\n",
        "        delta_w = np.zeros_like(self.weights)\n",
        "        delta_b = np.zeros_like(self.bias)\n",
        "\n",
        "        # Критерий останова (максимальное количество эпох)\n",
        "        for epoch in range(self.n_iters):\n",
        "            E_total = 0  # Обнуляем общую ошибку для каждой эпохи\n",
        "            delta_w = np.zeros_like(self.weights) # Обнуляем накопленные изменения весов\n",
        "            delta_b = np.zeros_like(self.bias) # Обнуляем накопленные изменения смещений\n",
        "\n",
        "            # Обработка каждого обучающего вектора\n",
        "            for i in range(n_samples):\n",
        "                X_m = X[i]\n",
        "                d_m = y[i]  # Желаемый выход (целевая переменная)\n",
        "\n",
        "                # Вычисление net_j и y_j (выхода)\n",
        "                net_j = np.dot(X_m, self.weights) + self.bias\n",
        "                y_j = self.activation_function(net_j)\n",
        "\n",
        "                # Вычисление ошибки E и добавление к общей ошибке\n",
        "                E_m = 0.5 * np.sum((d_m - y_j)**2)  # MSE (Mean Squared Error) для бинарной классификации\n",
        "                E_total += E_m\n",
        "\n",
        "                # Вычисление коррекции синаптических весов\n",
        "                dw = self.learning_rate * (d_m - y_j) * y_j * (1 - y_j) * X_m[:, np.newaxis] # Добавил np.newaxis для корректной размерности\n",
        "                db = self.learning_rate * (d_m - y_j) * y_j * (1 - y_j)\n",
        "\n",
        "                # Накопление изменений весов и смещений\n",
        "                delta_w += dw\n",
        "                delta_b += db\n",
        "\n",
        "            # Коррекция синаптических весов и смещений (после обработки всех векторов)\n",
        "            self.weights += delta_w / n_samples #  Делим на количество сэмплов, чтобы получить среднее изменение\n",
        "            self.bias += delta_b / n_samples # Делим на количество сэмплов, чтобы получить среднее изменение\n",
        "\n",
        "            print(f\"Эпоха {epoch+1}, общая ошибка: {E_total / n_samples}\")\n",
        "\n",
        "def load_mnist(digits=(0, 1), n_samples=None):\n",
        "    try:\n",
        "        mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "        X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "        X_filtered, y_filtered = [], []\n",
        "        for i in range(len(y)):\n",
        "            if y[i] in [str(digits[0]), str(digits[1])]:\n",
        "                X_filtered.append(X[i])\n",
        "                y_filtered.append(1 if y[i] == str(digits[1]) else 0)\n",
        "\n",
        "        X = np.array(X_filtered)\n",
        "        y = np.array(y_filtered)\n",
        "\n",
        "\n",
        "        # Ограничение количества образцов (если указано)\n",
        "        if n_samples is not None:\n",
        "            X = X[:n_samples]\n",
        "            y = y[:n_samples]\n",
        "\n",
        "        # Нормализация данных (масштабирование к диапазону [0, 1])\n",
        "        X = X / 255.0\n",
        "\n",
        "        return X, y\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при загрузке MNIST: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 1. Загрузка датасета MNIST\n",
        "    digits_to_use = (0, 1)\n",
        "    X, y = load_mnist(digits=digits_to_use, n_samples=2000)\n",
        "\n",
        "    if X is not None and y is not None:\n",
        "        # 2. Разделение на обучающую и тестовую выборки\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)\n",
        "\n",
        "        # 3. Создание и обучение персептрона\n",
        "        n_inputs = X_train.shape[1]\n",
        "        perceptron = Perceptron(n_inputs=n_inputs, learning_rate=0.1, n_iters=20, random_state=52)  # Установите random_state\n",
        "        perceptron.train(X_train, y_train)\n",
        "\n",
        "        # 4. Предсказание на тестовой выборке\n",
        "        y_pred = perceptron.predict(X_test)\n",
        "\n",
        "        # 5. Оценка точности\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Точность: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BidATdcf3rXT",
        "outputId": "17a972ec-9a8e-49f9-8395-7fac749d1a45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, общая ошибка: 0.12917019662054824\n",
            "Эпоха 2, общая ошибка: 0.10954412439758564\n",
            "Эпоха 3, общая ошибка: 0.09416507523632302\n",
            "Эпоха 4, общая ошибка: 0.08212288437889942\n",
            "Эпоха 5, общая ошибка: 0.07250520271106987\n",
            "Эпоха 6, общая ошибка: 0.06467665412218321\n",
            "Эпоха 7, общая ошибка: 0.058212576208401305\n",
            "Эпоха 8, общая ошибка: 0.05281509738598242\n",
            "Эпоха 9, общая ошибка: 0.04826454330628913\n",
            "Эпоха 10, общая ошибка: 0.04439376184571064\n",
            "Эпоха 11, общая ошибка: 0.04107338743377966\n",
            "Эпоха 12, общая ошибка: 0.038202296740886064\n",
            "Эпоха 13, общая ошибка: 0.035700859296323634\n",
            "Эпоха 14, общая ошибка: 0.03350594543295858\n",
            "Эпоха 15, общая ошибка: 0.03156716485592122\n",
            "Эпоха 16, общая ошибка: 0.029844012322924208\n",
            "Эпоха 17, общая ошибка: 0.02830369423765965\n",
            "Эпоха 18, общая ошибка: 0.02691946871654581\n",
            "Эпоха 19, общая ошибка: 0.025669373135823067\n",
            "Эпоха 20, общая ошибка: 0.02453524426385109\n",
            "Точность: 0.98\n"
          ]
        }
      ]
    }
  ]
}